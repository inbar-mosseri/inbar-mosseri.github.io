<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Inbar Mosseri</title>

    <meta name="author" content="Inbar Mosseri">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Inbar Mosseri
                </p>
                <p>I'm a Research Scientist leading a research group at <a href="https://deepmind.google/">Google DeepMind</a> in Tel-Aviv, focusing on image and video creation and editing using generative models. My role also includes co-leading Veo Capabilities.&nbsp;</p>
                <p>At the heart of my work is a deep passion for the intersection of AI and visual arts, where I'm constantly pushing the boundaries to explore how these cutting-edge technologies can revolutionize both academic research and the development of new product capabilities. </p>
<p style="text-align:center">
                  <a href="mailto:inbarzilai@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ifCcZ5IAAAAJ&hl=en">Google Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:70%;max-width:100%;object-fit:" alt="profile photo" src="images/inbarm.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
			
		
		  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research & Product Highlights</h2>
                
              </td>
            </tr>
          </tbody></table>
			
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr>
				<td style="padding:2%;width:33%;vertical-align:middle">
				  <a href="https://www.youtube.com/watch?v=wxLr02Dz2Sc&t=43s">
					<img src='images/lumiere_yt.png' width="100%" height="auto"></a>
				  
				</td>
				
				<td style="padding:2%;width:33%;vertical-align:middle">
					<a href="https://www.youtube.com/watch?v=Z1N53ZOv-ak">
				  <img src='images/best_take.png' width="104%" height="auto">
					</a>
				</td>
				<td style="padding:2%;width:34%;vertical-align:middle">
				<a href="https://blog.research.google/2018/04/looking-to-listen-audio-visual-speech.html">
				  <img src='images/l2l_blog.png' width="100%" height="auto">
					</a>
				</td>
<!--				<td style="padding:2%;width:75%;vertical-align:middle">-->
			</tr>
			<tr>
				<td style="padding:2%;width:33%;vertical-align:middle">
				  <a href="https://blog.youtube/news-and-events/made-on-youtube-2023/">
					<img src='images/made_by_yt.png' width="100%" height="auto"></a>
				  
				</td>
				
				<td style="padding:2%;width:33%;vertical-align:middle">
					<a href="https://blog.research.google/2022/01/introducing-stylex-new-approach-for.html">
				  <img src='images/stylex_blog.png' width="104%" height="auto">
					</a>
				</td>
				<td style="padding:2%;width:34%;vertical-align:middle">
				<a href="https://blog.research.google/2018/04/looking-to-listen-audio-visual-speech.html">
				  <img src='images/l2l_yt_blog.png' width="105%" height="auto">
					</a>
				</td>
<!--				<td style="padding:2%;width:75%;vertical-align:middle">-->
			</tr>
			<tr>
				<td style="padding:2%;width:33%;vertical-align:middle">
				  <a href="https://blog.google/products/pixel/snap-faster-hear-better-and-do-more-your-pixel/">
					<img src='images/ConvoMode_p6_3.gif' width="100%" height="auto"></a>
				  
				</td>
				
				<td style="padding:2%;width:33%;vertical-align:middle">
					<a href="https://blog.google/products/pixel/pixel-6s-camera-combines-hardware-software-and-ml/">
				  <img src='images/pixel6a.png' width="104%" height="auto">
					</a>
				</td>
				<td style="padding:2%;width:34%;vertical-align:middle;" align="center">
				<a href="https://blog.research.google/2017/05/neural-network-generated-illustrations.html">
				  <img src='images/f2c.gif' align="center" width="50%" height="auto">
					</a>
				</td>
			</tr>
			
		</tbody>
		</table>
		 
		  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my recent research work focuses on generative models for image and video. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


			<tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/tokenverse.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>TokenVerse: Versatile Multi-concept Personalization in Token Modulation Space</papertitle>
				  <br>
				  <a href="https://garibida.github.io/danielgaribi/">Daniel Garibi</a>,
				  <a href="https://www.linkedin.com/in/shahar-yadin-069725195/">Shahar Yadin</a>,
				  <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>,
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
				  <br>
				  <a href="https://cris.technion.ac.il/en/persons/tomer-michaeli">Tomer Michaeli</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  <br>
				  <em> SIGGRAPH, 2025 </em> <br>
				  <a href="https://lumiere-video.github.io/">Project</a>
				  <p></p>
				</td>
		    </tr>
			<tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/still-moving.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Still-Moving: Customized Video Generation without Customized Video Data&nbsp;</papertitle>
				  <br>
				  <a href="https://hila-chefer.github.io/">Hila Chefer</a>,
				  <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>,
				  <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://people.csail.mit.edu/mrub/">Michael Rubinstein</a>,
				  <br>
				  <a href="http://www.cs.tau.ac.il/~wolf/">Lior Wolf</a>,
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  <a href="https://cris.technion.ac.il/en/persons/tomer-michaeli">Tomer Michaeli</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>
				  <br>
				  <em> SIGGRAPH Asia (Journal), 2024 </em> <br>
				  <a href="https://lumiere-video.github.io/">Project</a>
				  <p></p>
				</td>
		    </tr>
			<tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/lumiere.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Lumiere: A Space-Time Diffusion Model for Video Generation</papertitle>
				  <br>
				  <a href="https://omerbt.github.io/">Omer Bartal</a>,
				  <a href="https://hila-chefer.github.io/">Hila Chefer</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://scholar.google.com/citations?user=LQvi5XAAAAAJ&hl=en">Charles Herrmann</a>,
				  <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
				  <br>
				  <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>,
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
				  
				  <a href="https://hurjunhwa.github.io/">Junhwa Hur </a>,
				  <a href="https://people.csail.mit.edu/yzli/">Yuanzhen Li</a>
				  <br>
				  <a href="https://cris.technion.ac.il/en/persons/tomer-michaeli">Tomer Michaeli</a>,
				  <a href="https://www.oliverwang.info/">Oliver Wang</a>,
				  <a href="https://deqings.github.io/">Deqing Sun</a>,
					<a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  <br>
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>
				  <br>
				  <em> SIGGRAPH Asia, 2024 </em> <br>
				  <a href="https://lumiere-video.github.io/">Project</a>
				  <p></p>
				</td>
		    </tr>  
			 <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/teaser_hidden_language.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>The Hidden Language of Diffusion Models</papertitle>
				  <br>
				  <a href="https://hila-chefer.github.io/">Hila Chefer</a>,
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <a href="https://mega002.github.io/">Mor Geva</a>,
				  <a href="https://www.linkedin.com/in/volodymyr-polosukhin-b685511b9/">Volodymyr Polosukhin</a>,
				  <br>
				  <a href="https://assafshocher.github.io/">Assaf Shocher</a>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="http://www.cs.tau.ac.il/~wolf/">Lior Wolf</a>
				  <br>
				  <em> ICLR, 2024 </em> <br>
				  <a href="https://arxiv.org/abs/2306.00966">Paper</a>
				  /
				  <a href="https://hila-chefer.github.io/Conceptor/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/imagic.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Imagic: Text-Based Real Image Editing with Diffusion Models</papertitle>
				  <br>
				  <a href="https://bahjat-kawar.github.io/">Bahjat Kawar</a>,
				  <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>,
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://research.google/people/107664/">Huiwen Chang</a>,
				  <br>
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>
				  <br>
				  <em> CVPR, 2023 </em> <br>
				  <a href="https://arxiv.org/abs/2210.09276">Paper</a>
				  /
				  <a href="https://imagic-editing.github.io/#">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/clip.png' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Teaching CLIP to Count to Ten</papertitle>
				  <br>
				  <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
				  <br>
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  <br>
				  <em> ICCV, 2023 </em> <br>
				  <a href="https://arxiv.org/abs/2210.09276">Paper</a>
				  /
				  <a href="https://imagic-editing.github.io/#">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/MyStyle.jpg' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>MyStyle: A Personalized Generative Prior</papertitle>
				  <br>
				  <a href="https://yotamnitzan.github.io/">Yotam Nitzan</a>,
				  <a href="https://kfiraberman.github.io/">Kfir Aberman</a>,
				  <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ&hl=en">Qiurui He</a>,
				  <a href="https://scholar.google.com/citations?user=GMVxiYgAAAAJ&hl=en">Michal Yarom</a>,
				  <br>
				  <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="https://scholar.google.co.il/citations?user=Zi5KiDsAAAAJ&hl=en">Yael Pritch</a>
				  <a href="https://danielcohenor.com/">Daniel Cohen-or</a>
				  <br>
				  <em> SIGGRAPH Asia, 2022 </em> <br>
				  <a href="https://mystyle-personalized-prior.github.io/">Paper</a>
				  /
				  <a href="https://mystyle-personalized-prior.github.io/">Project</a>
				  /
				  <a href="https://www.youtube.com/watch?v=axWo_9Gt47o">Video</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/self_distilled.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Self-Distilled StyleGAN: Towards Generation from Internet Photos </papertitle>
				  <br>
				  <a href="https://rmokady.github.io/">Ron Mokady</a>,
				  <a href="https://scholar.google.com/citations?user=GMVxiYgAAAAJ&hl=en">Michal Yarom</a>,
				  <a href="https://scholar.google.com/citations?hl=en&user=lbo_R54AAAAJ">Omer Tov</a>,
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <a href="https://danielcohenor.com/">Daniel Cohen-or</a>
				  <br>
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>
				  <br>
				  <em> SIGGRAPH, 2022 </em> <br>
				  <a href="https://arxiv.org/pdf/2202.12211.pdf">Paper</a>
				  /
				  <a href="https://self-distilled-stylegan.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/DSP.jpg' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Deep Saliency Prior for Reducing Visual Distraction </papertitle>
				  <br>
				  <a href="https://kfiraberman.github.io/">Kfir Aberman</a>,
				  <a href="https://scholar.google.com/citations?user=xrND8B8AAAAJ&hl=en">Junfeng He</a>,
				  <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <br>
				  <a href="https://scholar.google.co.il/citations?user=0VQ1sjcAAAAJ&hl=en">David E. Jacobs</a>,
				  <a href="https://scholar.google.com/citations?user=Du7j3mQAAAAJ&hl=en">Kai Kohlhoff</a>,
				  <a href="https://scholar.google.co.il/citations?user=Zi5KiDsAAAAJ&hl=en">Yael Pritch</a>,
				  <a href="https://people.csail.mit.edu/mrub/">Michael Rubinstein</a>
				  <br>
				  <em> CVPR, 2022 </em> <br>
				  <a href="https://deep-saliency-prior.github.io/saliency_driven_editing_preprint.pdf">Paper</a>
				  /
				  <a href="https://deep-saliency-prior.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/explaining.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Explaining in Style: Training a GAN to explain a classifier in StyleSpace </papertitle>
				  <br>
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>,
				  <a href="https://scholar.google.com/citations?user=GMVxiYgAAAAJ&hl=en">Michal Yarom</a>,
				  <a href="https://scholar.google.com/citations?user=hh5nOn4AAAAJ&hl=en">Yoav Wald</a>,
				  <a href="https://pluto.huji.ac.il/~galelidan/">Gal Elidan</a>,
				  <br>
				  <a href="https://u.cs.biu.ac.il/~avinatan/">Avinatan Hassidim</a>,
				  <a href="https://billf.mit.edu/">William T. Freeman</a>,
				  <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
				  <a href="https://en-exact-sciences.tau.ac.il/profile/gamir">Amir Globerson</a>,
				  <br>
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>
				  
				  <br>
				  <em> CVPR, 2021 </em> <br>
				  <a href="https://arxiv.org/abs/2104.13369">Paper</a>
				  /
				  <a href="https://explaining-in-style.github.io/">Project</a>
				  /
				  <a href="https://blog.research.google/2022/01/introducing-stylex-new-approach-for.html">Blog Post</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/dancing-adaptive.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>SpeedNet: Learning the Speediness in Videos</papertitle>
				  <br>
				  <a href="https://sagiebenaim.github.io">Sagie Benaim</a>,
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="https://billf.mit.edu/">William T. Freeman</a>,
					<br>
				  <a href="https://people.csail.mit.edu/mrub/">Michael Rubinstein</a>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
					<a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>
				  <br>
				  <em> CVPR, 2020 </em> <br>
				  <a href="https://arxiv.org/pdf/2004.06130.pdf">Paper</a>
				  /
				  <a href="https://speednet-cvpr20.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/semanticpyramid_after.gif' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Semantic Pyramid for Image Generation</papertitle>
				  <br>
				  <a href="https://assafshocher.github.io/">Assaf Shocher</a>,
				  <a href="https://yossigandelsman.github.io/">Yossi Gandelsman</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="https://scholar.google.com/citations?user=GMVxiYgAAAAJ&hl=en">Michal Yarom</a>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>,
				  <br>
				  <a href="https://billf.mit.edu/">William T. Freeman</a>,
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>
				  
				  <br>
				  <em> CVPR, 2020 </em> <br>
				  <a href="https://arxiv.org/pdf/2004.06130.pdf">Paper</a>
				  /
				  <a href="https://semantic-pyramid.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/speech2face.jpg' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Speech2face: Learning the face behind a voice </papertitle>
				  <br>
				  <a href="https://ami.postech.ac.kr/members/tae-hyun-oh">Tae-Hyun Oh</a>,
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
					
				  <a href="https://changilkim.com/">Changil Kim</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>, 
				  <a href="https://billf.mit.edu/">William T. Freeman</a>,
    			  <br>
				  <a href="https://people.csail.mit.edu/mrub/">Michael Rubinstein</a>,
				  <a href="https://cdfg.mit.edu/wojciech"> Wojciech Matusik</a>,
				  <br>
				  <em> CVPR, 2019 </em> <br>
				  <a href="https://arxiv.org/pdf/1905.09773">Paper</a>
				  /
				  <a href="https://speech2face.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/l2l_SIGGRAPH18.jpg' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation</papertitle>
				  <br>
				  <a href="http://www.cs.huji.ac.il/~arielephrat/">Ariel Efrat</a>,
					<strong><span style="font-size: 15px">Inbar Mosseri</span></strong>, 
				  <a href="https://scholar.google.com/citations?user=gypv57sAAAAJ">Oran Lang</a>,
				  <a href="https://www.weizmann.ac.il/math/dekel/home">Tali Dekel</a>,
				  Kevin Wilson,
				  <a href="https://u.cs.biu.ac.il/~avinatan/">Avinatan Hassidim</a>,
				  <br>
				  <a href="https://billf.mit.edu/">William T. Freeman</a>,
    			  <a href="https://people.csail.mit.edu/mrub/">Michael Rubinstein</a>
				  <br>
				  <em> SIGGRAPH, 2018 </em> <br>
				  <a href="https://arxiv.org/pdf/1804.03619.pdf">Paper</a>
				  /
				  <a href="https://looking-to-listen.github.io/">Project</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/XGAN.png' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Xgan: Unsupervised image-to-image translation for many-to-many mappings </papertitle>
				  <br>
				  <a href="https://ameroyer.github.io/">Amelie Royer</a>,
				  <a href="https://scholar.google.com/citations?user=wtRVnsYAAAAJ&hl=en">Konstantinos Bousmalis</a>,
				  Stephan Gouws, 
				  <a href="https://scholar.google.com/citations?user=xD8Af4sAAAAJ&hl=en">Fred Bertsch</a>,
    			  <br>
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>, 
				  <a href="https://people.csail.mit.edu/fcole/"> Forrester Cole</a>,
				  <a href="https://scholar.google.com/citations?user=MxxZkEcAAAAJ&hl=en">Kevin Murphy</a>
				  <br>
				  <em> ICLR, 2018 </em> <br>
				  <a href="https://arxiv.org/abs/1711.05139">Paper</a>
				  <p></p>
				</td>
			  </tr> 
			  
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/normalized_faces.png' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Synthesizing normalized faces from facial identity features</papertitle>
				  <br>
				  <a href="https://people.csail.mit.edu/fcole/"> Forrester Cole</a>,
				  David Belanger,
				  <a href="https://scholar.google.com/citations?user=_MEuWIMAAAAJ&hl=en">Dilip Krishnan</a>,
				  Aaron Sarna 
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <br>
					<a href="https://billf.mit.edu/">William T. Freeman</a>,
				  <br>
				  <em> CVPR, 2017 </em> <br>
				  <a href="https://arxiv.org/abs/1701.04851">Paper</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/combining_the_power.jpg' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Combining the Power of Internal and External Denoising</papertitle>
				  <br>
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="https://scholar.google.com/citations?user=64RHiS4AAAAJ&hl=en"> Maria Zontak</a>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>
				  <br>
				  <em> ICCP, 2013 </em> <br>
				  <a href="https://www.weizmann.ac.il/math/irani/sites/math.irani/files/publications/combining.pdf">Paper</a>
				  <p></p>
				</td>
			  </tr> 
			  <tr>
				<td style="padding:2%;width:25%;vertical-align:middle">
				  <img src='images/seperating_the_singal.png' width="100%" height="auto">
				</td>
				<td style="padding:2%;width:75%;vertical-align:middle">
				  <papertitle>Separating signal from noise using patch recurrence across scales</papertitle>
				  <br>
				  <a href="https://scholar.google.com/citations?user=64RHiS4AAAAJ&hl=en"> Maria Zontak</a>,
				  <strong><span style="font-size: 15px">Inbar Mosseri</span></strong>,
				  <a href="http://www.weizmann.ac.il/math/irani/">Michal Irani</a>
				  <br>
				  <em> CVPR, 2013 </em> <br>
				  <a href="https://www.wisdom.weizmann.ac.il/~vision/_repository/Zontak_Mosseri_Irani_CVPR2013.pdf">Paper</a> / 
				  <a href="https://www.wisdom.weizmann.ac.il/~vision/MultiScaleDenoising.html">Project</a>
				  <p></p>
				</td>
			  </tr> 


            
          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="1">
                    <a href="https://jonbarron.info/">webpage template from Jon Barron</a>
                  </font>
                </p>
              </td>
            </tr>
			</tbody>
		  </table>
        </td>
      </tr>
    </table>
  </body>
</html>
